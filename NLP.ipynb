{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/srirakshareddy/language-model/blob/main/NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kA79cXhA-pK0",
        "outputId": "f9884842-8b50-4216-f5a5-aa587fcfdaec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPv_JEf8ZvIb"
      },
      "source": [
        "### Data preprocessing\n",
        "\n",
        "In this section we will write code to load data and clean (tokenize) it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2apYXiYZxog",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92ee9b89-b167-4737-bca2-03707279f921"
      },
      "source": [
        "# Import libraries for preprocessing\n",
        "import os\n",
        "import numpy as np\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ukW4E7MfgZtX"
      },
      "source": [
        "[Natural Language Toolkit](https://www.nltk.org/)\n",
        "\n",
        "NLTK is a leading platform for building Python programs to work with human language data. It provides easy-to-use interfaces to over 50 corpora and lexical resources such as WordNet, along with a suite of text processing libraries for classification, tokenization, stemming, tagging, parsing, and semantic reasoning, wrappers for industrial-strength NLP libraries, and an active discussion forum."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "naV4YPZvZ3JO"
      },
      "source": [
        "# Tokenizer class\n",
        "\n",
        "\n",
        "class Tokenizer:\n",
        "  def __init__(self, tokenize_type='basic', lowercase=False):\n",
        "    self.lowercase = lowercase  # If this is True, convert text to lowercase while tokenizing.\n",
        "    self.type = tokenize_type\n",
        "    self.vocab = []\n",
        "    \n",
        "\n",
        "  \"\"\"This simple tokenizer splits the text using whitespace.\"\"\"\n",
        "  def basicTokenize(self, string):\n",
        "    words = string.split()\n",
        "    return words\n",
        "\n",
        "  ## NLTK's word_tokenize() function. ###\n",
        "  ### returns also a list of words similar to basicTokenize function\n",
        "  def nltkTokenize(self, string):\n",
        "\n",
        "     words = nltk.tokenize.word_tokenize(string)\n",
        "     return words\n",
        "    \n",
        "\n",
        "  def tokenize(self, string):\n",
        "    if self.lowercase:\n",
        "      string = string.lower()\n",
        "    if self.type == 'basic':\n",
        "      tokens = self.basicTokenize(string)\n",
        "    elif self.type == 'nltk':\n",
        "      tokens = self.nltkTokenize(string)\n",
        "    else:\n",
        "      raise ValueError('Unknown tokenization type.')    \n",
        "\n",
        "\n",
        "    # Populate vocabulary\n",
        "    self.vocab += [w for w in set(tokens) if w not in self.vocab]\n",
        "\n",
        "    return tokens\n",
        "\n",
        "  ### Fill in this function to return the top k words in the corpus and their corresponding frequencies. \n",
        "  ### Top k are sorted in the corpus according to frequency. ###\n",
        "  ### return a list\n",
        "  def countTopWords(self, words, k):\n",
        "\n",
        "    word_counter = {}\n",
        "    for word in words:\n",
        "      if word in word_counter:\n",
        "        word_counter[word] += 1\n",
        "      else:\n",
        "        word_counter[word] = 1\n",
        "    \n",
        "    top_counter = sorted(word_counter, key = word_counter.get, reverse = True)\n",
        "    top_k = top_counter[:k]\n",
        "    return top_k\n",
        "\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qxQp2VJaZhq"
      },
      "source": [
        "# Function for reading the corpus\n",
        "def readCorpus(filename, tokenizer):  \n",
        "  with open(filename) as f:\n",
        "    words = tokenizer.tokenize(f.read())\n",
        "  return words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXYBlcTyagBQ"
      },
      "source": [
        "### Language Modeling and Smoothing\n",
        "In this section we will first compute the bigram counts and estimate bigram probabilities. We will then implement Laplace add-alpha (also called add-k) smoothing to modify the probabilities. In class we have seen a special case of add-alpha smoothing which is the add-1 smoothing where alpha is equal to 1 ($\\alpha = 1$). In this assignment we will try different values of alpha for smoothing.\n",
        "Estimating a bigram conditional probabilty of the next word $w_n$ given the prefix word $w_{n-1}$ using add-alpha smoothing is expressed as follows:\n",
        "\n",
        "\n",
        "\n",
        "<h1><center>$\\hat{P}_{add-\\alpha}(w_n|w_{n-1}) = \\frac{C(w_{n-1}w_n)+\\alpha}{C(w_{n-1})+\\alpha|V|}$</center></h1>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K47R17s-ao6k"
      },
      "source": [
        "# Import libraries\n",
        "# Feel free to import as many as you like\n",
        "import sys\n",
        "import os\n",
        "import numpy as np\n",
        "import argparse\n",
        "from tqdm import tqdm\n",
        "from collections import Counter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BK7uqvcEa49P"
      },
      "source": [
        "# Class definition for language modeling\n",
        "\n",
        "class LanguageModel:\n",
        "  def __init__(self, vocab, n=2, smoothing=None, smoothing_param=None):\n",
        "    assert n >=2, \"This code does not allow you to train unigram models.\"\n",
        "    self.vocab = vocab\n",
        "    self.token_to_idx = {word: i for i, word in enumerate(self.vocab)}\n",
        "    self.n = n\n",
        "    self.smoothing = smoothing    \n",
        "    self.smoothing_param = smoothing_param\n",
        "    self.x = None      # Holds the bigram counts\n",
        "    self.bi_prob = None        # Holds the computed bigram probabilities.\n",
        "\n",
        "    assert smoothing is None or smoothing_param is not None, \"Forgot to specify a smoothing parameter?\"\n",
        "\n",
        "\n",
        "  \"\"\"Compute basic bigram probabilities (without any smoothing)\"\"\"\n",
        "  def computeBigramProb(self):\n",
        "    self.bi_prob = self.bi_counts.copy()\n",
        "\n",
        "    for i, _ in enumerate(tqdm(self.bi_prob, desc=\"Estimating bigram probabilities\")):\n",
        "      cnt = np.sum(self.bi_prob[i])\n",
        "      if cnt > 0:\n",
        "        self.bi_prob[i] /= cnt\n",
        "        \n",
        "  ### Compute bigram probabilities with Add-alpha smoothing###\n",
        "  ### You can follow the same structure of the above function computeBigramProb(self)\n",
        "  ### For an efficient implementation try to vectorize as much as possible and avoid nested for loops\n",
        "  ### Not necessary to return something here \n",
        "  def computeBigramProbAddAlpha(self, alpha=0.001):\n",
        "\n",
        "    self.bi_prob = self.bi_counts.copy()\n",
        "\n",
        "    for i, _ in enumerate(tqdm(self.bi_prob, desc=\"Estimating bigram probabilities\")):\n",
        "      cnt = np.sum(self.bi_prob[i])\n",
        "      denominator = np.add(cnt, alpha * len(self.vocab))\n",
        "      numerator = np.add(self.bi_prob[i], alpha)\n",
        "      self.bi_prob[i] = numerator/denominator\n",
        "\n",
        "\n",
        "\n",
        "  \"\"\"Train a basic n-gram language model\"\"\"\n",
        "  def train(self, corpus):\n",
        "    if self.n==2:\n",
        "      self.bi_counts = np.zeros((len(self.vocab), len(self.vocab)), dtype=float)\n",
        "    else:\n",
        "      raise ValueError(\"Only bigram model has been implemented so far.\")\n",
        "    \n",
        "    # Convert to token indices.\n",
        "    corpus = [self.token_to_idx[w] for w in corpus]\n",
        "\n",
        "    # Gather counts\n",
        "    for i, idx in enumerate(tqdm(corpus[:1-self.n], desc=\"Counting\")):\n",
        "      self.bi_counts[idx][corpus[i+1]] += 1\n",
        "\n",
        "    # Pre-compute the probabilities.\n",
        "    if not self.smoothing:\n",
        "      self.computeBigramProb()\n",
        "    elif self.smoothing == 'addAlpha':\n",
        "      self.computeBigramProbAddAlpha(self.smoothing_param)\n",
        "    else:\n",
        "      raise ValueError(\"Unknown smoothing type.\")\n",
        "\n",
        "\n",
        "\n",
        "  def test(self, corpus):\n",
        "    \n",
        "    logprob = 0.\n",
        "\n",
        "    # Convert to token indices.\n",
        "    corpus = [self.token_to_idx[w] for w in corpus]\n",
        "\n",
        "    for i, idx in enumerate(tqdm(corpus[:1-self.n], desc=\"Evaluating\")):\n",
        "      logprob += np.log(self.bi_prob[idx, corpus[i+1]])\n",
        "\n",
        "    logprob /= len(corpus[:1-self.n])\n",
        "\n",
        "    # Compute perplexity\n",
        "    ppl = np.exp(-logprob)\n",
        "\n",
        "    return ppl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkIAhWqYeUgL"
      },
      "source": [
        "### Instantiate a tokenizer and LM, and calculate perplexity\n",
        "This section contains driver code for learning a language model and evaluating it on a train and dev corpus."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nILv3Tyleb54"
      },
      "source": [
        "def runLanguageModel(train_corpus,\n",
        "                     val_corpus,\n",
        "                     train_fraction,\n",
        "                     tokenizer,\n",
        "                     smoothing_type=None,\n",
        "                     smoothing_param='0.0'):\n",
        "\n",
        "  # Instantiate the language model.\n",
        "  lm = LanguageModel(tokenizer.vocab, n=2, smoothing=smoothing_type, smoothing_param=smoothing_param)\n",
        "\n",
        "  # Figure out index for a specific percentage of train corpus to use. \n",
        "  train_idx = int(train_fraction * len(train_corpus))\n",
        "\n",
        "  lm.train(train_corpus[:train_idx])\n",
        "\n",
        "  train_ppl = lm.test(train_corpus[:train_idx])\n",
        "  val_ppl = lm.test(val_corpus)\n",
        "\n",
        "  print(\"Train perplexity: %f, Val Perplexity: %f\" %(train_ppl, val_ppl))\n",
        "\n",
        "  return [train_ppl, val_ppl]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8hSR_9VczRI"
      },
      "source": [
        "### Load the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HiATPjKWB5X9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd44465e-9255-4d9a-c962-e6c0f7bf5580"
      },
      "source": [
        "#Mount drive to access files in gdrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syUH84NUc1rL"
      },
      "source": [
        "#YOU NEED TO CHANGE PATH OF train_file AND val_file ACCORDING TO WHERE YOU STORE THEM IN YOUR gdrive.\n",
        "\n",
        "\n",
        "train_file = '/content/brown-train.txt'\n",
        "\n",
        "val_file = '/content/brown-val.txt'\n",
        "\n",
        "# Instantiate a basic tokenizer\n",
        "basic_tokenizer = Tokenizer(tokenize_type='basic', lowercase=True)\n",
        "\n",
        "# Read the corpus and store\n",
        "train_corpus = readCorpus(train_file, basic_tokenizer)\n",
        "val_corpus = readCorpus(val_file, basic_tokenizer)\n",
        "\n",
        "# Instantiate nltk tokenizer\n",
        "nltk_tokenizer = Tokenizer(tokenize_type='nltk', lowercase=True)\n",
        "\n",
        "# Read the corpus and store\n",
        "train_corpus_nltk = readCorpus(train_file, nltk_tokenizer)\n",
        "val_corpus_nltk = readCorpus(val_file, nltk_tokenizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrTFdG6WJnDO"
      },
      "source": [
        "#### Part of the code for sub-part (a)\n",
        "Print top 10 most frequent words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0UzPXzve2q_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f729b91-c6e3-4226-e3de-2f49a60c7439"
      },
      "source": [
        "### Print the top 10 words in the corpus both when using a basic tokenizer and when using nltk tokenizer \n",
        "### IMPORTANT: complete the function countTopWords within the Tokenizer class first.\n",
        "### Use a similar syntax to this: print(\"Top 10 words basic: %s\" % TO FILL)\n",
        "\n",
        "#nltk tokenizer\n",
        "print(\"Top 10 words nltk:\")\n",
        "print(nltk_tokenizer.countTopWords(val_corpus_nltk,10))\n",
        "print(\"------------------------------------------------\")\n",
        "# basic tokenizer\n",
        "print(\"Top 10 words basic:\")\n",
        "print(basic_tokenizer.countTopWords(val_corpus,10))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 10 words nltk:\n",
            "['unk', 'the', 'of', ',', '.', 'and', 'to', 'in', 'a', 'is']\n",
            "------------------------------------------------\n",
            "Top 10 words basic:\n",
            "['unk', 'the', 'of', 'and', 'to', 'in', 'a', 'is', 'that', 'was']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtrPOKd1vvyx"
      },
      "source": [
        "### Experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anwiyViHMCTt"
      },
      "source": [
        "#### Plot the frequency of words\n",
        "Code for sub-part (b)\n",
        "\n",
        "Using the nltkTokenize function you wrote, make a plot of the frequencies of words in the training corpus, ordered by their rank, i.e. the most frequent word first, the second most word next, and so on on the x axis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1xEdVHxMl0n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "outputId": "2162aae8-5f07-4e04-fc01-f0b86b1768e4"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "### Code for plotting the frequency of words\n",
        "\n",
        "tokenized_words = []\n",
        "for word in train_corpus_nltk:\n",
        "  tokenized_words.append(nltk_tokenizer.nltkTokenize(word))\n",
        "\n",
        "freq = {}\n",
        "\n",
        "for word in tokenized_words:\n",
        "  if word[0] not in freq:\n",
        "    freq[word[0]] = 1\n",
        "  else:\n",
        "    freq[word[0]] += 1\n",
        "\n",
        "word_ranks = sorted(freq.items(), key=lambda freq: freq[1], reverse=True)\n",
        "\n",
        "word_ranks = word_ranks[:50]\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (20,5)\n",
        "fig = plt.figure()\n",
        "ax = fig.add_axes([0,0,1,1])\n",
        "freqs = []\n",
        "values = []\n",
        "\n",
        "for idx,value in enumerate(word_ranks):\n",
        "  freqs.append(value[0])\n",
        "  values.append(value[1])\n",
        "\n",
        "ax.bar(freqs,values)\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAWeJQ8VdBHU"
      },
      "source": [
        "#### Report the train and test perplexity after learning the language model\n",
        "Code for sub-part (c)\n",
        "\n",
        "Use the basicTokenize function and bigram language model ($n = 2$) without smoothing for this question.\n",
        "\n",
        "Train the language model and report its perplexity on the train and validation sets. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xH79REFCcNRH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40f3968d-e3e3-48b0-bae9-bcec6b2cb4e5"
      },
      "source": [
        "### Train bigram language model on the whole train corpus (train fraction = 1) and evaluate perplexity on both the training and the validation corpus  \n",
        "\n",
        "runLanguageModel(train_corpus_nltk, val_corpus_nltk, train_fraction = 1, tokenizer = nltk_tokenizer, smoothing_type=None, smoothing_param='0.0')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Counting: 100%|██████████| 700042/700042 [00:00<00:00, 846637.06it/s]\n",
            "Estimating bigram probabilities: 100%|██████████| 14880/14880 [00:00<00:00, 28581.10it/s]\n",
            "Evaluating: 100%|██████████| 700042/700042 [00:01<00:00, 449541.31it/s]\n",
            "Evaluating:   0%|          | 0/175232 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:75: RuntimeWarning: divide by zero encountered in log\n",
            "Evaluating: 100%|██████████| 175232/175232 [00:00<00:00, 351726.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train perplexity: 70.348557, Val Perplexity: inf\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[70.34855680853418, inf]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4ntdVf2j24K"
      },
      "source": [
        "#### Add-alpha smoothing\n",
        "Code for sub-part (d)\n",
        "\n",
        "Use the basicTokenize function and bigram language model ($n = 2$) with smoothing for this question.\n",
        "\n",
        "Implement Laplace (add-$\\alpha$) smoothing within the appropriate function provided (computeBigramAddAlpha in LanguageModel class) and train model with add-alpha smoothing on the whole train set for different alpha values $[10^{-5},10^{-4},10^{-3},10^{-2},10^{-1},1,1.5,2]$.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmMeDg-lkQkC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27a5f2ef-fe06-4b1a-9253-1ec591e772c4"
      },
      "source": [
        "### For different values of alpha train bigram language model with smoothing on the whole train corpus (train fraction = 1)\n",
        "### and evaluate perplexity on both the training and the validation corpus\n",
        "### Plot the perplexity on train and validation sets as a function of alpha.\n",
        "### Values of alpha specified above\n",
        "\n",
        "\n",
        "print(\"Parameter = 10^-5\")\n",
        "runLanguageModel(train_corpus_nltk, val_corpus_nltk, train_fraction = 1, tokenizer = nltk_tokenizer, smoothing_type='addAlpha', smoothing_param=0.00001)\n",
        "\n",
        "print(\"Parameter = 10^-4\")\n",
        "runLanguageModel(train_corpus_nltk, val_corpus_nltk, train_fraction = 1, tokenizer = nltk_tokenizer, smoothing_type='addAlpha', smoothing_param=0.0001)\n",
        "\n",
        "print(\"Parameter = 10^-3\")\n",
        "runLanguageModel(train_corpus_nltk, val_corpus_nltk, train_fraction = 1, tokenizer = nltk_tokenizer, smoothing_type='addAlpha', smoothing_param=0.001)\n",
        "\n",
        "print(\"Parameter = 10^-2\")\n",
        "runLanguageModel(train_corpus_nltk, val_corpus_nltk, train_fraction = 1, tokenizer = nltk_tokenizer, smoothing_type='addAlpha', smoothing_param=0.01)\n",
        "\n",
        "print(\"Parameter = 10^-1\")\n",
        "runLanguageModel(train_corpus_nltk, val_corpus_nltk, train_fraction = 1, tokenizer = nltk_tokenizer, smoothing_type='addAlpha', smoothing_param=0.1)\n",
        "\n",
        "print(\"Parameter = 1\")\n",
        "runLanguageModel(train_corpus_nltk, val_corpus_nltk, train_fraction = 1, tokenizer = nltk_tokenizer, smoothing_type='addAlpha', smoothing_param=1)\n",
        "\n",
        "print(\"Parameter = 1.5\")\n",
        "runLanguageModel(train_corpus_nltk, val_corpus_nltk, train_fraction = 1, tokenizer = nltk_tokenizer, smoothing_type='addAlpha', smoothing_param=1.5)\n",
        "\n",
        "print(\"Parameter = 2\")\n",
        "runLanguageModel(train_corpus_nltk, val_corpus_nltk, train_fraction = 1, tokenizer = nltk_tokenizer, smoothing_type='addAlpha', smoothing_param=2)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter = 10^-5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Counting: 100%|██████████| 700042/700042 [00:00<00:00, 870526.15it/s]\n",
            "Estimating bigram probabilities: 100%|██████████| 14880/14880 [00:00<00:00, 20806.85it/s]\n",
            "Evaluating: 100%|██████████| 700042/700042 [00:01<00:00, 445176.26it/s]\n",
            "Evaluating: 100%|██████████| 175232/175232 [00:00<00:00, 462513.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train perplexity: 70.561778, Val Perplexity: 1623.907183\n",
            "Parameter = 10^-4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Counting: 100%|██████████| 700042/700042 [00:00<00:00, 824754.11it/s]\n",
            "Estimating bigram probabilities: 100%|██████████| 14880/14880 [00:00<00:00, 21315.24it/s]\n",
            "Evaluating: 100%|██████████| 700042/700042 [00:01<00:00, 445125.98it/s]\n",
            "Evaluating: 100%|██████████| 175232/175232 [00:00<00:00, 416701.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train perplexity: 72.287369, Val Perplexity: 939.249112\n",
            "Parameter = 10^-3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Counting: 100%|██████████| 700042/700042 [00:00<00:00, 845036.68it/s]\n",
            "Estimating bigram probabilities: 100%|██████████| 14880/14880 [00:00<00:00, 21334.55it/s]\n",
            "Evaluating: 100%|██████████| 700042/700042 [00:01<00:00, 445498.52it/s]\n",
            "Evaluating: 100%|██████████| 175232/175232 [00:00<00:00, 416121.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train perplexity: 83.394263, Val Perplexity: 614.213532\n",
            "Parameter = 10^-2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Counting: 100%|██████████| 700042/700042 [00:00<00:00, 875613.60it/s]\n",
            "Estimating bigram probabilities: 100%|██████████| 14880/14880 [00:00<00:00, 21667.56it/s]\n",
            "Evaluating: 100%|██████████| 700042/700042 [00:01<00:00, 439424.46it/s]\n",
            "Evaluating: 100%|██████████| 175232/175232 [00:00<00:00, 437346.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train perplexity: 131.878479, Val Perplexity: 542.582409\n",
            "Parameter = 10^-1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Counting: 100%|██████████| 700042/700042 [00:00<00:00, 863436.93it/s]\n",
            "Estimating bigram probabilities: 100%|██████████| 14880/14880 [00:00<00:00, 21594.97it/s]\n",
            "Evaluating: 100%|██████████| 700042/700042 [00:01<00:00, 441271.66it/s]\n",
            "Evaluating: 100%|██████████| 175232/175232 [00:00<00:00, 438644.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train perplexity: 319.847737, Val Perplexity: 733.307078\n",
            "Parameter = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Counting: 100%|██████████| 700042/700042 [00:00<00:00, 857613.23it/s]\n",
            "Estimating bigram probabilities: 100%|██████████| 14880/14880 [00:00<00:00, 20488.62it/s]\n",
            "Evaluating: 100%|██████████| 700042/700042 [00:01<00:00, 441200.51it/s]\n",
            "Evaluating: 100%|██████████| 175232/175232 [00:00<00:00, 444046.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train perplexity: 1070.802723, Val Perplexity: 1499.772976\n",
            "Parameter = 1.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Counting: 100%|██████████| 700042/700042 [00:00<00:00, 884657.26it/s]\n",
            "Estimating bigram probabilities: 100%|██████████| 14880/14880 [00:00<00:00, 21732.72it/s]\n",
            "Evaluating: 100%|██████████| 700042/700042 [00:01<00:00, 445340.34it/s]\n",
            "Evaluating: 100%|██████████| 175232/175232 [00:00<00:00, 438716.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train perplexity: 1336.011470, Val Perplexity: 1756.969971\n",
            "Parameter = 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Counting: 100%|██████████| 700042/700042 [00:00<00:00, 830400.71it/s]\n",
            "Estimating bigram probabilities: 100%|██████████| 14880/14880 [00:00<00:00, 20979.20it/s]\n",
            "Evaluating: 100%|██████████| 700042/700042 [00:01<00:00, 442151.85it/s]\n",
            "Evaluating: 100%|██████████| 175232/175232 [00:00<00:00, 426011.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train perplexity: 1559.949976, Val Perplexity: 1972.551353\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1559.9499757369956, 1972.5513534864501]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    }
  ]
}